% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/models.R
\name{build_xgboost}
\alias{build_xgboost}
\title{XGBoost algorithm}
\usage{
build_xgboost(
  data,
  eta = 0.3,
  nrounds = 75,
  max_depth = 6,
  subsample = 0.5,
  colsample_bytree = 0.5,
  eval_metric = "error",
  objective = "binary:logistic"
)
}
\arguments{
\item{data}{list of data.frames; containing the training and testing sets for the model}

\item{eta}{float; control the learning rate; scale the contribution of each tree by a factor of 0 < eta < 1}

\item{nrounds}{int; number of iterations;lower value for eta implies larger value}

\item{max_depth}{int; maximum depth of a tree}

\item{subsample}{float; subsample ratio of the training instance; 0.5 prevents overfitting}

\item{colsample_bytree}{float; subsample ratio of columns when constructing each tree}

\item{eval_metric}{chr; evaluation metrics for validation data}

\item{objective}{chr; specify the learning task and the corresponding learning objective}
}
\value{
list of parameters created by the XGBoost model
}
\description{
XGBoost algorithm
}
